<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">

  <!-- If for some reason you are using IE, use edge -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!-- So bootstrap isn't horrible, set the width -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="mask-icon" href="/images/favicons/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="theme-color" content="#ffffff">

  <title>Scheduling</title>

  <!-- Reference a CDN so this is properly cached in the browser forever. Unless they clean out the
       Cache this will incur no load time. Ideally we should put a security checksum but that breaks
       Firefox development sometimes -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" crossorigin="anonymous">

  <!-- Asynchronously load the code style sheet because we want everything loaded as fast as possible
       Also tag with ?v=time to bust the cache of any browser so updates appear -->
  <link async rel="stylesheet" href="/css/code-style.css?v='2018-11-28 20:00:31 -0600'">

  <!-- Don't load async because this will make the page render faster, plus the file is small.
       Also do the same cache busting magic here -->
  <link rel="stylesheet" href="/css/main.css?v='2018-11-28 20:00:31 -0600'">

</head>

<body>
<!-- Always shows a header, even in smaller screens. -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">

            <!-- Navigation button as html so we don't have to resize images -->
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>


            <!-- Inline tux for speed -->
            <a id="tuxlink"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAJCAMAAAA4jZ0cAAAAM1BMVEX///8CAgQMDAwsLCw0NDSjbQCkbQC+vbzOkwDU1NTlrADqvADxtgD0vQD12wD+/vz+//yBSdYEAAAAAXRSTlMAQObYZgAAADFJREFUCB0FwQkCQDAQBLCsq6g1/v9aCVQBthUwX8BIgStZCpUvKXSSLs6eyd0Pdg5+JwkBVyC74QYAAAAASUVORK5CYII=" title="Tux" alt="Tux" style="margin-left: 1em; width: 24px; filter: drop-shadow(1px 1px 0 white) drop-shadow(1px -1px 0 white) drop-shadow(-1px 1px 0 white) drop-shadow(-1px -1px 0 white); margin-top: 1em;"/></a>

            <a class="navbar-brand navbar-link normal" href="/">CS 241: System Programming</a>
            <a class="navbar-brand navbar-link small" href="/">CS 241</a>
        </div>

        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            
            <li>
                <a class="navbar-link" href="/assignments.html">Assignments</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/quiz_topics.html">Quizzes</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/help.html">Help!</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/schedule.html">Schedule</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/honors.html">Honors</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/staff.html">The Crew</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/search.html">Search</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/wikibook/home.html">Wikibook</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/wikibook_project/Index.html">Wikibook Project</a>
            </li>
            
          </ul>
        </div>
        </div>
</nav>


<div class="container-fluid">
  <div class="row">
    <div class="col-md-2 col-sm-1 col-xs-0"></div>
    <div class="col-md-8 col-sm-10 col-xs-12">
      <div class="wrapper">
        <div class="pad"><div class="card">
          <div class="title">
            <div class="speaker-wrapper">
              <button onclick="speak()" class="speaker" alt="Read Page"></button>
            </div>
            <h1>
              Scheduling

              
            </h1>
          </div>
          <div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
            
            
          </div></div></div>
        </div></div>
      </div>
      
      <div id="content">
          <div class="wrapper">

</div>
          <div class="wrapper">
<ul>
  <li>
<a href="#scheduling" class="fancy-link wiki-link">Scheduling</a>
    <ul>
      <li>
<a href="#measurements" class="fancy-link wiki-link">Measurements</a>
        <ul>
          <li><a href="#what-is-preemption" class="fancy-link wiki-link">What is preemption?</a></li>
          <li><a href="#which-schedulers-suffer-from-starvation" class="fancy-link wiki-link">Which schedulers suffer from starvation?</a></li>
          <li><a href="#why-might-a-process-or-thread-be-placed-on-the-ready-queue" class="fancy-link wiki-link">Why might a process (or thread) be placed on the ready queue?</a></li>
        </ul>
      </li>
      <li>
<a href="#measures-of-efficiency" class="fancy-link wiki-link">Measures of Efficiency</a>
        <ul>
          <li><a href="#what-is-the-convoy-effect" class="fancy-link wiki-link">What is the Convoy Effect?</a></li>
          <li><a href="#linux-scheduling" class="fancy-link wiki-link">Linux Scheduling</a></li>
        </ul>
      </li>
      <li>
<a href="#scheduling-algorithms" class="fancy-link wiki-link">Scheduling Algorithms</a>
        <ul>
          <li><a href="#shortest-job-first-sjf" class="fancy-link wiki-link">Shortest Job First (SJF)</a></li>
          <li><a href="#preemptive-shortest-job-first-psjf" class="fancy-link wiki-link">Preemptive Shortest Job First (PSJF)</a></li>
          <li><a href="#first-come-first-served-fcfs" class="fancy-link wiki-link">First Come First Served (FCFS)</a></li>
          <li><a href="#round-robin-rr" class="fancy-link wiki-link">Round Robin (RR)</a></li>
          <li><a href="#priority" class="fancy-link wiki-link">Priority</a></li>
        </ul>
      </li>
      <li><a href="#topics" class="fancy-link wiki-link">Topics</a></li>
      <li><a href="#questions" class="fancy-link wiki-link">Questions</a></li>
    </ul>
  </li>
</ul>

<p>[1][] <span> </span></p>



<p>CPU Scheduling is the problem of efficiently selecting which process to run on a system’s CPU cores. In a busy system, there will be more ready-to-run processes than there are CPU cores, so the system kernel must evaluate which processes should be scheduled to run and which processes should be executed later. The system must also decide whether or not it should take a particular process and pause its execution – along with any associated threads. The balance comes from stopping processes often enough where you have a responsive computer but infrequently enough where the programs themselves are not spending a lot of cycles context switching. It is a hard balance it get right.</p>

<p>The additional complexity of multi-threaded and multiple CPU cores are considered a distraction to this initial exposition so are ignored here. Another gotcha for non-native speakers is the dual meanings of “Time”: The word “Time” can be used in both clock and elapsed duration context. For example “The arrival time of the first process was 9:00am.” and, “The running time of the algorithm is 3 seconds”.</p>

<p>One clarification that we will make is that our scheduling will mainly deal with short term or cpu scheduling. That means we will assume that the processes are in memory and ready to go. The other types of scheduling are long and medium term. Long term schedulers act as gatekeepers to the processing world. When a process requests another process to be executed, it can either tell tell the process yes, no, or wait. The medium term scheduler deals with the caveats of moving a process from the paused state in memory to the paused state on disk when there are too many processes or some process are known not to be used for a significant amount of CPU cycles (think about a process that only checks something once an hour).</p>

<div class="pad"><div class="card">
<div class="title"><h2 id="measurements" class="title-text">Measurements<a class="anchor title-text" href="#measurements">#</a>
</h2></div>





















<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>Scheduling effects the performance of the system, specifically the <em>latency</em> and <em>throughput</em> of the system. The throughput might be measured by a system value, for example the I/O throughput - the number of bits written per second, or number of small processes that can complete per unit time. The latency might be measured by the response time – elapse time before a process can start to send a response – or wait time or turnaround time –the elapsed time to complete a task. Different schedulers offer different optimization trade-offs that may or may not be appropriate to desired use. There is no optimal scheduler for all possible environments and goals. For example ‘shortest-job-first’ will minimize total wait time across all jobs but in interactive (UI) environments it would be preferable to minimize response time at the expense of some throughput, while FCFS seems intuitively fair and easy to implement but suffers from the Convoy Effect. Arrival time is the time at which a process first arrives at the ready queue, and is ready to start executing. If a CPU is idle, the arrival time would also be the starting time of execution.</p>
<h3 id="what-is-preemption" class="title-text">What is preemption?</h3>
<p>Without preemption processes will run until they are unable to utilize the CPU any further. For example the following conditions would remove a process from the CPU and the CPU would be available to be scheduled for other processes: The process terminates due to a signal, is blocked waiting for concurrency primitive, or exits normally. Thus once a process is scheduled it will continue even if another process with a high priority (e.g. shorter job) appears on the ready queue.</p>
<p>With preemption, the existing processes may be removed immediately if a more preferable process is added to the ready queue. For example, suppose at t=0 with a Shortest Job First scheduler there are two processes (P1 P2) with 10 and 20 ms execution times. P1 is scheduled. P1 immediately creates a new process P3, with execution time of 5 ms, which is added to the ready queue. Without preemption, P3 will run 10ms later (after P1 has completed). With preemption, P1 will be immediately evicted from the CPU and instead placed back in the ready queue, and P3 will be executed instead by the CPU.</p>
<h3 id="which-schedulers-suffer-from-starvation" class="title-text">Which schedulers suffer from starvation?</h3>
<p>Any scheduler that uses a form of prioritization can result in starvation because earlier processes may never be scheduled to run (assigned a CPU). For example with SJF, longer jobs may never be scheduled if the system continues to have many short jobs to schedule. It all depends on the <a href="https://en.wikipedia.org/wiki/Scheduling_(computing)#Types_of_operating_system_schedulers" class="fancy-link wiki-link">type of scheduler</a>.</p>
<h3 id="why-might-a-process-or-thread-be-placed-on-the-ready-queue" class="title-text">Why might a process (or thread) be placed on the ready queue?</h3>
<p>A process is placed on the ready queue when it is able to use a CPU. Some examples include:</p>
<ul>
  <li>
    <p>A process was blocked waiting for a <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/read" class="fancy-link">read</a></code></span> from storage or socket to complete and data is now available.</p>
  </li>
  <li>
    <p>A new process has been created and is ready to start.</p>
  </li>
  <li>
    <p>A process thread was blocked on a synchronization primitive (condition variable, semaphore, mutex lock) but is now able to continue.</p>
  </li>
  <li>
    <p>A process is blocked waiting for a system call to complete but a signal has been delivered and the signal handler needs to run.</p>
  </li>
</ul>
<p>Similar examples can be generated when considering threads.</p>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="measures-of-efficiency" class="title-text">Measures of Efficiency<a class="anchor title-text" href="#measures-of-efficiency">#</a>
</h2></div>





























<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>First some definitions</p>
<ol>
  <li>
    <p><span><code class="highlighter-rouge">start_time</code></span> is the wall-clock start time of the process (CPU starts working on it)</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">end_time</code></span> is the end wall-clock of the process (CPU finishes the process)</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">run_time</code></span> is the total amount of CPU time required</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">arrival_time</code></span> is the time the process enters the scheduler (CPU may not start working on it)</p>
  </li>
</ol>
<p>Here are measures of efficiency</p>
<ol>
  <li>
    <p><span><code class="highlighter-rouge">Turnaround Time</code></span> is the total time from when you the process arrives to when it ends. <span><code class="highlighter-rouge">end_time - arrival_time</code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">Response Time</code></span> is the total latency (time) that it takes from when the process arrives to when the CPU actually starts working on it. <span><code class="highlighter-rouge">start_time - arrival_time</code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">Wait Time</code></span> is the <em>total</em> wait time i.e. the total time that a process is on the ready queue. A common mistake is to believe it is only the initial waiting time in the ready queue. If a CPU intensive process with no I/O takes 7 minutes of CPU time to complete but required 9 minutes of wall-clock time to complete we can conclude that it was placed on the ready-queue for 2 minutes. For those 2 minutes the process was ready to run but had no CPU assigned. It does not matter when the job was waiting, the wait time is 2 minutes. <span><code class="highlighter-rouge">end_time - arrival_time - run_time</code></span></p>
  </li>
</ol>
<h3 id="what-is-the-convoy-effect" class="title-text">What is the Convoy Effect?</h3>
<p>“The Convoy Effect is where I/O intensive processes are continually backed up, waiting for CPU-intensive processes that hog the CPU. This results in poor I/O performance, even for processes that have tiny CPU needs.”</p>
<p>Suppose the CPU is currently assigned to a CPU intensive task and there is a set of I/O intensive processes that are in the ready queue. These processes require just a tiny amount of CPU time but they are unable to proceed because they are waiting for the CPU-intensive task to be removed from the processor. These processes are starved until the the CPU bound process releases the CPU. But the CPU will rarely be released (for example in the case of a FCFS scheduler, we must wait until the processes is blocked due to an I/O request). The I/O intensive processes can now finally satisfy their CPU needs, which they can do quickly because their CPU needs are small and the CPU is assigned back to the CPU-intensive process again. Thus the I/O performance of the whole system suffers through an indirect effect of starvation of CPU needs of all processes.</p>
<p>This effect is usually discussed in the context of FCFS scheduler, however a round robin scheduler can also exhibit the Convoy effect for long time-quanta.</p>
<h3 id="linux-scheduling" class="title-text">Linux Scheduling</h3>
<p>As of February 2016, Linux by default uses the <em>Completely Fair Scheduler</em> for CPU scheduling and the Budget Fair Scheduling “BFQ” for I/O scheduling. Appropriate scheduling can have a significant impact on throughput and latency. Latency is particularly important for interactive and soft-real time applications such as audio and video streaming. See the discussion and comparative benchmarks <a href="https://lkml.org/lkml/2014/5/27/314" class="fancy-link wiki-link">here</a> for more information.</p>
<p>Here is how the CFS schedules</p>
<ul>
  <li>
    <p>The CPU creates a Red-Black tree with the processes virtual runtime (runtime / nice_value) and sleeper fairness flag (if the process is waiting on something give it the CPU when it is done waiting).</p>
  </li>
  <li>
    <p>(Nice values are the kernel’s way of giving priority to certain processes, the lower nice value the higher priority)</p>
  </li>
  <li>
    <p>The kernel chooses the lowest one based on this metric and schedules that process to run next, taking it off the queue. Since the red-black tree is self balancing this operation is guaranteed (O(log(n))) (selecting the min process is the same runtime)</p>
  </li>
</ul>
<p>Although it is called the Fair Scheduler there are a fair bit of problems.</p>
<ul>
  <li>
    <p>Groups of processes that are scheduled may have imbalanced loads so the scheduler roughly distributes the load. When another CPU gets free it can only look at the average load of a group schedule not the individual cores. So the free CPU may not take the work from a CPU that is burning so long as the average is fine.</p>
  </li>
  <li>
    <p>If a group of processes is running on non-adjacent cores then there is a bug. If the two cores are more than a hop away, the load balancing algorithm won’t even consider that core. Meaning if a CPU is free and a CPU that is doing more work is more than a hop away, it won’t take the work (may have been patched).</p>
  </li>
  <li>
    <p>After a thread goes to sleep on a subset of cores, when it wakes up it can only be scheduled on the cores that it was sleeping on. If those cores are now busy, the thread will have to wait on them, wasting opportunities to use other idle cores.</p>
  </li>
  <li>
    <p>To read more on the problems of the Fair Scheduler, read <a href="https://blog.acolyer.org/2016/04/26/the-linux-scheduler-a-decade-of-wasted-cores" class="fancy-link wiki-link">here</a>.</p>
  </li>
</ul>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="scheduling-algorithms" class="title-text">Scheduling Algorithms<a class="anchor title-text" href="#scheduling-algorithms">#</a>
</h2></div>

























































































<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>For all the examples,</p>
<p>Process 1: Runtime 1000ms</p>
<p>Process 2: Runtime 2000ms</p>
<p>Process 3: Runtime 3000ms</p>
<p>Process 4: Runtime 4000ms</p>
<p>Process 5: Runtime 5000ms</p>
<h3 id="shortest-job-first-sjf" class="title-text">Shortest Job First (SJF)</h3>
<p><img src="https://raw.githubusercontent.com/illinois-cs241/wikibook-project/master/scheduling/images/sjf.png"></p>
<ul>
  <li>
    <p>P1 Arrival: 0ms</p>
  </li>
  <li>
    <p>P2 Arrival: 0ms</p>
  </li>
  <li>
    <p>P3 Arrival: 0ms</p>
  </li>
  <li>
    <p>P4 Arrival: 0ms</p>
  </li>
  <li>
    <p>P5 Arrival: 0ms</p>
  </li>
</ul>
<p>The processes all arrive at the start and the scheduler schedules the job with the shortest total CPU time. The glaring problem is that this scheduler needs to know how long this program will run over time before it ran the program.</p>
<p>Technical Note: A realistic SJF implementation would not use the total execution time of the process but the burst time (the total CPU time including future computational execution before the process will no longer be ready to run). The expected burst time can be estimated by using an exponentially decaying weighted rolling average based on the previous burst time but for this exposition we will simplify this discussion to use the total running time of the process as a proxy for the burst time.</p>
<p><strong>Advantages</strong></p>
<ol>
  <li>Shorter jobs tend to get run first</li>
</ol>
<p><strong>Disadvantages</strong></p>
<ol>
  <li>Needs algorithm to be omniscient</li>
</ol>
<h3 id="preemptive-shortest-job-first-psjf" class="title-text">Preemptive Shortest Job First (PSJF)</h3>
<p>Preemptive shortest job first is like shortest job first but if a new job comes in with a shorter runtime than the total runtime of the current job, it is run instead. (If it is equal like our example our algorithm can choose). The scheduler uses the <em>total</em> runtime of the process. If you want the shortest <em>remaining</em> time left, that is a variant of PSJF called Shortest Remaining Time First (SRTF).</p>
<p><img src="https://raw.githubusercontent.com/illinois-cs241/wikibook-project/master/scheduling/images/psjf.png"></p>
<ul>
  <li>
    <p>P2 at 0ms</p>
  </li>
  <li>
    <p>P1 at 1000ms</p>
  </li>
  <li>
    <p>P5 at 3000ms</p>
  </li>
  <li>
    <p>P4 at 4000ms</p>
  </li>
  <li>
    <p>P3 at 5000ms</p>
  </li>
</ul>
<p>Here’s what our algorithm does. It runs P2 because it is the only thing to run. Then P1 comes in at 1000ms, P2 runs for 2000ms, so our scheduler preemptively stops P2, and let’s P1 run all the way through (this is completely up to the algorithm because the times are equal). Then, P5 Comes in – since there are no processes running, the scheduler will run process 5. P4 comes in, and since the runtimes are equal P5, the scheduler stops P5 and runs P4. Finally P3 comes in, preempts P4, and runs to completion. Then P4 runs, then P5 runs.</p>
<p><strong>Advantages</strong></p>
<ol>
  <li>Ensures shorter jobs get run first</li>
</ol>
<p><strong>Disadvantages</strong></p>
<ol>
  <li>Need to know the runtime again</li>
</ol>
<h3 id="first-come-first-served-fcfs" class="title-text">First Come First Served (FCFS)</h3>
<p><img src="https://raw.githubusercontent.com/illinois-cs241/wikibook-project/master/scheduling/images/fcfs.png"></p>
<ul>
  <li>
    <p>P2 at 0ms</p>
  </li>
  <li>
    <p>P1 at 1000ms</p>
  </li>
  <li>
    <p>P5 at 3000ms</p>
  </li>
  <li>
    <p>P4 at 4000ms</p>
  </li>
  <li>
    <p>P3 at 5000ms</p>
  </li>
</ul>
<p>Processes are scheduled in the order of arrival. One advantage of FCFS is that scheduling algorithm is simple: the ready queue is a just a FIFO (first in first out) queue. FCFS suffers from the Convoy effect. Here P2 Arrives, then P1 arrives, then P5, then P4, then P3. You can see the convoy effect for P5.</p>
<p><strong>Advantages</strong></p>
<ul>
  <li>
    <p>Simple algorithm and implementation</p>
  </li>
  <li>
    <p>Context switches infrequent when there are long running processes</p>
  </li>
  <li>
    <p>No starvation if all processes are guarenteed to terminate</p>
  </li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
  <li>
    <p>Simple algorithm and implementation</p>
  </li>
  <li>
    <p>Context switches infrequent when there are long running processes</p>
  </li>
</ul>
<h3 id="round-robin-rr" class="title-text">Round Robin (RR)</h3>
<p>Processes are scheduled in order of their arrival in the ready queue. However after a small time step a running process will be forcibly removed from the running state and placed back on the ready queue. This ensures that a long-running process can not starve all other processes from running. The maximum amount of time that a process can execute before being returned to the ready queue is called the time quanta. In the limit of large time quanta (where the time quanta is longer than the running time of all processes) round robin will be equivalent to FCFS.</p>
<p><img src="https://raw.githubusercontent.com/illinois-cs241/wikibook-project/master/scheduling/images/rr.png"></p>
<ul>
  <li>
    <p>P1 Arrival: 0ms</p>
  </li>
  <li>
    <p>P2 Arrival: 0ms</p>
  </li>
  <li>
    <p>P3 Arrival: 0ms</p>
  </li>
  <li>
    <p>P4 Arrival: 0ms</p>
  </li>
  <li>
    <p>P5 Arrival: 0ms</p>
  </li>
</ul>
<p>Quantum = 1000ms</p>
<p>Here all processes arrive at the same time. P1 is run for 1 quantum and is finished. P2 for one quantum; then, it is stopped for P3. After all other processes run for a quantum we cycle back to P2 until all the processes are finished.</p>
<p><strong>Advantages</strong></p>
<ol>
  <li>Ensures some notion of fairness</li>
</ol>
<p><strong>Disadvantages</strong></p>
<ol>
  <li>Large number of processes = Lots of switching</li>
</ol>
<h3 id="priority" class="title-text">Priority</h3>
<p>Processes are scheduled in the order of priority value. For example, a navigation process might be more important to execute than a logging process.</p>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="topics" class="title-text">Topics<a class="anchor title-text" href="#topics">#</a>
</h2></div>



<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1"><ul>
  <li>
    <p>Scheduling Algorithms</p>
  </li>
  <li>
    <p>Measures of Efficiency</p>
  </li>
</ul></div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="questions" class="title-text">Questions<a class="anchor title-text" href="#questions">#</a>
</h2></div>


<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1"><ul>
  <li>
    <p>What is scheduling?</p>
  </li>
  <li>
    <p>What is turnaround time? Response Time? Wait time?</p>
  </li>
  <li>
    <p>What is the convoy effect?</p>
  </li>
  <li>
    <p>Which algorithms have the best turnaround/response/wait time on average</p>
  </li>
</ul></div></div></div>
</div></div>
</div>
          
          <div class="wrapper">
</div>
      </div>
      <div class="col-md-2 col-sm-1 col-xs-0"></div>
    </div>
  </div>
  <script>
    var github_repo = "illinois-cs241/illinois-cs241.github.io";
    var github_path = "_wikibook_project/Scheduling.md";
  </script>
  <!-- Mathjax takes a while to load so do a lazy load to so we can get accessibility -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" crossorigin="anonymous"></script>

<!-- Again bust cache on the main.js file -->
<script src="/js/main.js?v='2018-11-28 20:00:31 -0600'"></script>

<script>
<footer class="">

<div class="container-fluid">
<div class="shadow"></div>

</div>

</footer>

</body>
</html>
