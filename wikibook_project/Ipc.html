<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">

  <!-- If for some reason you are using IE, use edge -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <!-- So bootstrap isn't horrible, set the width -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="mask-icon" href="/images/favicons/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="theme-color" content="#ffffff">

  <title>Ipc</title>

  <!-- Reference a CDN so this is properly cached in the browser forever. Unless they clean out the
       Cache this will incur no load time. Ideally we should put a security checksum but that breaks
       Firefox development sometimes -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" crossorigin="anonymous">

  <!-- Asynchronously load the code style sheet because we want everything loaded as fast as possible
       Also tag with ?v=time to bust the cache of any browser so updates appear -->
  <link async rel="stylesheet" href="/css/code-style.css?v='2018-11-28 20:00:31 -0600'">

  <!-- Don't load async because this will make the page render faster, plus the file is small.
       Also do the same cache busting magic here -->
  <link rel="stylesheet" href="/css/main.css?v='2018-11-28 20:00:31 -0600'">

</head>

<body>
<!-- Always shows a header, even in smaller screens. -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">

            <!-- Navigation button as html so we don't have to resize images -->
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>


            <!-- Inline tux for speed -->
            <a id="tuxlink"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAJCAMAAAA4jZ0cAAAAM1BMVEX///8CAgQMDAwsLCw0NDSjbQCkbQC+vbzOkwDU1NTlrADqvADxtgD0vQD12wD+/vz+//yBSdYEAAAAAXRSTlMAQObYZgAAADFJREFUCB0FwQkCQDAQBLCsq6g1/v9aCVQBthUwX8BIgStZCpUvKXSSLs6eyd0Pdg5+JwkBVyC74QYAAAAASUVORK5CYII=" title="Tux" alt="Tux" style="margin-left: 1em; width: 24px; filter: drop-shadow(1px 1px 0 white) drop-shadow(1px -1px 0 white) drop-shadow(-1px 1px 0 white) drop-shadow(-1px -1px 0 white); margin-top: 1em;"/></a>

            <a class="navbar-brand navbar-link normal" href="/">CS 241: System Programming</a>
            <a class="navbar-brand navbar-link small" href="/">CS 241</a>
        </div>

        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            
            <li>
                <a class="navbar-link" href="/assignments.html">Assignments</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/quiz_topics.html">Quizzes</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/help.html">Help!</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/schedule.html">Schedule</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/honors.html">Honors</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/staff.html">The Crew</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/search.html">Search</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/wikibook/home.html">Wikibook</a>
            </li>
            
            <li>
                <a class="navbar-link" href="/wikibook_project/Index.html">Wikibook Project</a>
            </li>
            
          </ul>
        </div>
        </div>
</nav>


<div class="container-fluid">
  <div class="row">
    <div class="col-md-2 col-sm-1 col-xs-0"></div>
    <div class="col-md-8 col-sm-10 col-xs-12">
      <div class="wrapper">
        <div class="pad"><div class="card">
          <div class="title">
            <div class="speaker-wrapper">
              <button onclick="speak()" class="speaker" alt="Read Page"></button>
            </div>
            <h1>
              Ipc

              
            </h1>
          </div>
          <div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
            
            
          </div></div></div>
        </div></div>
      </div>
      
      <div id="content">
          <div class="wrapper">

</div>
          <div class="wrapper">
<ul>
  <li>
<a href="#interprocess-communication" class="fancy-link wiki-link">Interprocess Communication</a>
    <ul>
      <li>
<a href="#mmu-and-translating-addresses" class="fancy-link wiki-link">MMU and Translating Addresses</a>
        <ul>
          <li><a href="#terminology" class="fancy-link wiki-link">Terminology</a></li>
          <li><a href="#multi-level-page-tables" class="fancy-link wiki-link">Multi-level page tables</a></li>
          <li><a href="#page-table-disadvantages" class="fancy-link wiki-link">Page Table Disadvantages</a></li>
        </ul>
      </li>
      <li>
<a href="#advanced-frames-and-page-protections" class="fancy-link wiki-link">Advanced Frames and Page Protections</a>
        <ul>
          <li><a href="#read-only-bit" class="fancy-link wiki-link">Read-only bit</a></li>
          <li><a href="#dirty-bit" class="fancy-link wiki-link">Dirty bit</a></li>
          <li><a href="#execution-bit" class="fancy-link wiki-link">Execution bit</a></li>
          <li><a href="#page-faults" class="fancy-link wiki-link">Page Faults</a></li>
        </ul>
      </li>
      <li>
<a href="#pipes" class="fancy-link wiki-link">Pipes</a>
        <ul>
          <li><a href="#pipe-gotchas" class="fancy-link wiki-link">Pipe Gotchas</a></li>
          <li><a href="#why-is-my-pipe-hanging" class="fancy-link wiki-link">Why is my pipe hanging?</a></li>
          <li><a href="#race-condition-with-named-pipes" class="fancy-link wiki-link">Race condition with named pipes</a></li>
          <li><a href="#what-is-filling-up-the-pipe-what-happens-when-the-pipe-becomes-full" class="fancy-link wiki-link">What is filling up the pipe? What happens when the pipe becomes full?</a></li>
          <li><a href="#are-pipes-process-safe" class="fancy-link wiki-link">Are pipes process safe?</a></li>
          <li><a href="#the-lifetime-of-pipes" class="fancy-link wiki-link">The lifetime of pipes</a></li>
          <li><a href="#want-to-use-pipes-with-printf-and-scanf-use-fdopen" class="fancy-link wiki-link">Want to use pipes with printf and scanf? Use fdopen!</a></li>
          <li><a href="#when-do-i-need-two-pipes" class="fancy-link wiki-link">When do I need two pipes?</a></li>
        </ul>
      </li>
      <li>
<a href="#named-pipes" class="fancy-link wiki-link">Named Pipes</a>
        <ul>
          <li><a href="#how-do-i-create-named-pipes" class="fancy-link wiki-link">How do I create named pipes?</a></li>
          <li><a href="#two-types-of-files" class="fancy-link wiki-link">Two types of files</a></li>
          <li><a href="#how-do-i-tell-how-large-a-file-is" class="fancy-link wiki-link">How do I tell how large a file is?</a></li>
          <li><a href="#but-try-not-to-do-this" class="fancy-link wiki-link">But try not to do this</a></li>
          <li><a href="#what-happens-if-a-child-process-closes-a-filestream-using-fclose-or-close" class="fancy-link wiki-link">What happens if a child process closes a filestream using fclose or close?</a></li>
          <li><a href="#how-about-mmap-for-files" class="fancy-link wiki-link">How about mmap for files?</a></li>
          <li><a href="#for-every-mmap" class="fancy-link wiki-link">For every mmap</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>[1][] <span> </span></p>



<p><span><strong>Epigraph</strong></span></p>

<p>In very simple embedded systems and early computers, processes directly access memory i.e. “Address 1234” corresponds to a particular byte stored in a particular part of physical memory. For example the IBM 709 had to read and write directly to a tape with no level of abstraction . Even in systems after that, it was hard to adopt virtual memory because virtual memory required the whole fetch cycle to be altered through hardware – a change many manufacturers still thought was expensive. In the PDP-10, a workaround was used by using different registers for each process and then virtual memory was added later. In modern systems, this is no longer the case. Instead each process is isolated, and there is a translation process between the address of a particular CPU instruction or piece of data of a process and the actual byte of physical memory (“RAM”). Memory addresses no longer map to physical addresses; the process runs inside virtual memory. Virtual memory not only keeps processes safe (because one process cannot directly read or modify another process’s memory) it also allows the system to efficiently allocate and re-allocate portions of memory to different processes. The modern process of translating memory is as follows.</p>

<ol>
  <li>
    <p>A process makes a memory request</p>
  </li>
  <li>
    <p>The circuit first checks the Translation Lookaside Buffer (TLB) if the address page is cached into memory. It skips to the reading from/writing to phase if found otherwise the request goes to the MMU.</p>
  </li>
  <li>
    <p>The Memory Management Unit (MMU) performs the address translation. If the translation succeeds (more on that later), the page get pulled from RAM – conceptually the entire page isn’t loaded up. The result is cached in the TLB.</p>
  </li>
  <li>
    <p>The CPU performs the operation by either reading from the physical address or writing to the address.</p>
  </li>
</ol>

<div class="pad"><div class="card">
<div class="title"><h2 id="mmu-and-translating-addresses" class="title-text">MMU and Translating Addresses<a class="anchor title-text" href="#mmu-and-translating-addresses">#</a>
</h2></div>















































<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>The Memory Management Unit is part of the CPU, and it converts a virtual memory address into a physical address. There is a sort of pseudocode associated with the MMU.</p>
<ol>
  <li>
    <p>Receive address</p>
  </li>
  <li>
    <p>Try to translate address according to the programmed scheme</p>
  </li>
  <li>
    <p>If the translation fails, report an invalid address</p>
  </li>
  <li>
    <p>Otherwise,</p>

    <ol>
      <li>
        <p>If the page exists in memory, check if the process has permissions to perform the operation on the page meaning the process has access to the page, and it is reading from the page/writing to a page that is not marked as read only.</p>

        <ol>
          <li>
            <p>If so then provide the address, cache the results in the TLB</p>
          </li>
          <li>
            <p>Otherwise trigger a hardware interrupt. The kernel will most likely send a SIGSEGV or a Segmentation Violation.</p>
          </li>
        </ol>
      </li>
      <li>
        <p>If the page doesn’t exist in memory, generate an Interrupt.</p>

        <ol>
          <li>
            <p>The kernel could realize that this page could either be not allocated or on disk. If it fits the mapping, allocate the page and try the operation again.</p>
          </li>
          <li>
            <p>Otherwise, this is an invalid access and the kernel will most likely send a SIGSEGV to the process.</p>
          </li>
        </ol>
      </li>
    </ol>
  </li>
</ol>
<p>Imagine you had a 32 bit machine, meaning pointers are 32 bits. They can address (2^{32}) different locations or 4GB of memory where one address is one byte. Imagine we had a large table - here’s the clever part - stored in memory! For every possible address (all 4 billion of them) we will store the ‘real’ i.e.  physical address. Each physical address will need 4 bytes (to hold the 32 bits). This scheme would require 16 billion bytes to store all of entries. Oops - our lookup scheme would consume all of the memory that we could possibly buy for our 4GB machine. We need to do better than this. Our lookup table better be smaller than the memory we have otherwise we will have no space left for our actual programs and operating system data. The solution is to chunk memory into small regions called ‘pages’ and ‘frames’ and use a lookup table for each page.</p>
<p>A <strong>page</strong> is a block of virtual memory. A typical block size on Linux operating system is 4KB or (2^{12}) addresses, though you can find examples of larger blocks. So rather than talking about individual bytes we can talk about blocks of 4KBs, each block is called a page. We can also number our pages (“Page 0” “Page 1” etc). Let’s do a sample calculation of how many pages are there assume page size of 4KB.</p>
<p>For a 32 bit machine, (2^{32}) address / (2^{12}) (address/page) = (2^{20}) pages.</p>
<p>For a 64 bit machine, (2^{64}) / (2^{12}) = (2^{52}), which is roughly (10^{15}) pages.</p>
<h3 id="terminology" class="title-text">Terminology</h3>
<p>A <strong>frame</strong> (or sometimes called a ‘page frame’) is a block of <em>physical memory</em> or RAM (=Random Access Memory). This kind of memory is occasionally called ‘primary storage’ in contrast with lower, secondary storage such as spinning disks that have lower access times. A frame is the same number of bytes as a virtual page. If a 32 bit machine has (2^{32} B) of RAM, then there will be the same number of them in the addressable space of the machine. It’s unlikely that a 64 bit machine will ever have (2^{64}) bytes of RAM.</p>
<p>A <strong>page table</strong> is a mapping between a page to the frame. For example Page 1 might be mapped to frame 45, page 2 mapped to frame 30. Other frames might be currently unused or assigned to other running processes, or used internally by the operating system.</p>
<p>A simple page table could be imagined as an array.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>For a 32 bit machine with 4KB pages, each entry needs to hold a frame number - i.e. 20 bits because we calculated there are (2^{20}) frames. That’s 2.5 bytes per entry! In practice, we’ll round that up to 4 bytes per entry and find a use for those spare bits. With 4 bytes per entry x (2^{20}) entries = 4 MB of physical memory are required to hold the page table For a 64 bit machine with 4KB pages, each entry needs 52 bits. Let’s round up to 64 bits (8 bytes) per entry. With (2^{52}) entries thats (2^{55}) bytes (roughly 40 peta bytes…) Oops our page table is too large In 64 bit architectures memory addresses are sparse, so we need a mechanism to reduce the page table size, given that most of the entries will never be used.</p>
<p>An <strong>offset</strong> take a particular page and looks up a byte by adding it to the start of the page. Remember our page table maps pages to frames, but each page is a block of contiguous addresses. How do we calculate which particular byte to use inside a particular frame? The solution is to re-use the lowest bits of the virtual memory address directly. For example, suppose our process is reading the following address- <span><code class="highlighter-rouge">VirtualAddress = 11110000111100001111000010101010 (binary)</code></span></p>
<p>On a machine with page size 256 Bytes, then the lowest 8 bits (10101010) will be used as the offset. The remaining upper bits will be the page number (111100001111000011110000).</p>
<h3 id="multi-level-page-tables" class="title-text">Multi-level page tables</h3>
<p>Multi-level pages are one solution to the page table size issue for 64 bit architectures. We’ll look at the simplest implementation - a two level page table. Each table is a list of pointers that point to the next level of tables, not all sub-tables need to exist. An example, two level page table for a 32 bit architecture is shown below-</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>VirtualAddress = 11110000111111110000000010101010 (binary)
                 |-Index1-||        ||          | 10 bit Directory index
                           |-Index2-||          | 10 bit Sub-table index
                                     |--offset--| 12 bit offset (passed directly to RAM)
</code></pre></div></div>
<p>In the above scheme, determining the frame number requires two memory reads: The topmost 10 bits are used in a directory of page tables. If 2 bytes are used for each entry, we only need 2KB to store this entire directory. Each subtable will point to physical frames (i.e. required 4 bytes to store the 20 bits). However, for processes with only tiny memory needs, we only need to specify entries for low memory address (for the heap and program code) and high memory addresses (for the stack). Each subtable is 1024 entries x 4 bytes i.e. 4KB for each subtable.</p>
<p>Thus the total memory overhead for our multi-level page table has shrunk from 4MB (for the single level implementation) to 3 frames of memory (12KB) ! Here’s why: We need at least one frame for the high level directory and two frames for just two sub-tables. One sub-table is necessary for the low addresses (program code, constants and possibly a tiny heap), the other sub-table is for higher addresses used by the environment and stack. In practice, real programs will likely need more sub-table entries, as each subtable can only reference 1024*4KB = 4MB of address space but the main point still stands - we have significantly reduced the memory overhead required to perform page table look ups.</p>
<h3 id="page-table-disadvantages" class="title-text">Page Table Disadvantages</h3>
<p>Yes - Significantly ! (But thanks to clever hardware, usually no…) Compared to reading or writing memory directly. For a single page table, our machine is now twice as slow! (Two memory accesses are required) For a two-level page table, memory access is now three times as slow. (Three memory accesses are required)</p>
<p>To overcome this overhead, the MMU includes an associative cache of recently-used virtual-page-to-frame lookups. This cache is called the TLB (“translation lookaside buffer”). Everytime a virtual address needs to be translated into a physical memory location, the TLB is queried in parallel to the page table. For most memory accesses of most programs, there is a significant chance that the TLB has cached the results. However if a program does not have good cache coherence (for example is reading from random memory locations of many different pages) then the TLB will not have the result cache and now the MMU must use the much slower page table to determine the physical frame.</p>
<p>This may be how one splits up a multi level page table.</p>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="advanced-frames-and-page-protections" class="title-text">Advanced Frames and Page Protections<a class="anchor title-text" href="#advanced-frames-and-page-protections">#</a>
</h2></div>





<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>Frames be shared between processes! In addition to storing the frame number, the page table can be used to store whether a process can write or only read a particular frame. Read only frames can then be safely shared between multiple processes. For example, the C-library instruction code can be shared between all processes that dynamically load the code into the process memory. Each process can only read that memory. Meaning that if you try to write to a read-only page in memory you will get a <span><code class="highlighter-rouge">SEGFAULT</code></span>. That is why sometimes memory accesses segfault and sometimes they don’t, it all depends on if your hardware says that you can access.</p>
<p>In addition, processes can share a page with a child process using the <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/mmap" class="fancy-link">mmap</a></code></span> system call. <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/mmap" class="fancy-link">mmap</a></code></span> is an interesting call because instead of tying each virtual address to a physical frame, it ties it to something else. That something else can be a file, a GPU unit, or any other memory mapped operation that you can think of! Writing to the memory address may write through to the device or the write may be paused by the operating system but this is a very powerful abstraction because often the operating system is able to perform optimizations (multiple processes memory mapping the same file can have the kernel create one mapping). In addition, it is common to store at least read-only, modification and execution information.</p>
<div class="pad"><div class="card">
<h4 id="read-only-bit">Read-only bit</h4>

<p>The read-only bit marks the page as read-only. Attempts to write to the page will cause a page fault. The page fault will then be handled by the Kernel. Two examples of the read-only page include sharing the c runtime library between multiple processes (for security you wouldn’t want to allow one process to modify the library); and Copy-On-Write where the cost of duplicating a page can be delayed until the first write occurs.</p>

</div></div>
<div class="pad"><div class="card">
<h4 id="dirty-bit">Dirty bit</h4>

<p><a href="http://en.wikipedia.org/wiki/Page_table#Page_table_data" class="fancy-link wiki-link">Page Table</a> The dirty bit allows for a performance optimization. A page on disk that is paged in to physical memory, then read from, and subsequently paged out again does not need to be written back to disk, since the page hasn’t changed. However, if the page was written to after it’s paged in, its dirty bit will be set, indicating that the page must be written back to the backing store. This strategy requires that the backing store retain a copy of the page after it is paged in to memory. When a dirty bit is not used, the backing store need only be as large as the instantaneous total size of all paged-out pages at any moment. When a dirty bit is used, at all times some pages will exist in both physical memory and the backing store.</p>

</div></div>
<div class="pad"><div class="card">
<h4 id="execution-bit">Execution bit</h4>

<p>The execution bit defines whether bytes in a page can be executed as CPU instructions. By disabling a page, it prevents code that is maliciously stored in the process memory (e.g. by stack overflow) from being easily executed. (further reading: <a href="http://en.wikipedia.org/wiki/NX_bit#Hardware_background" class="fancy-link wiki-link">background</a>)</p>

<h3 id="page-faults" class="title-text">Page Faults</h3>

<p>A page fault is when a running program tries to access some virtual memory in its address space that is not mapped to physical memory. Page faults will also occur in other situations. There are three types of Page Faults</p>

<ol>
  <li>
    <p><strong>Minor</strong> If there is no mapping yet for the page, but it is a valid address. This could be memory asked for by <span><code class="highlighter-rouge">sbrk(2)</code></span> but not written to yet meaning that the operating system can wait for the first write before allocating space. The OS simply makes the page, loads it into memory, and moves on.</p>
  </li>
  <li>
    <p><strong>Major</strong> If the mapping to the page is not in memory but on disk. What this will do is swap the page into memory and swap another page out. If this happens frequently enough, your program is said to <em>thrash</em> the MMU.</p>
  </li>
  <li>
    <p><strong>Invalid</strong> When you try to write to a non-writable memory address or read to a non-readable memory address. The MMU generates an invalid fault and the OS will usually generate a <span><code class="highlighter-rouge">SIGSEGV</code></span> meaning segmentation violation meaning that you wrote outside the segment that you could write to.</p>
  </li>
</ol>

</div></div>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="pipes" class="title-text">Pipes<a class="anchor title-text" href="#pipes">#</a>
</h2></div>

































































<!-- -->







































<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<p>Inter process communication is any way for one process to talk to another process. You’ve already seen one form of this virtual memory! A piece of virtual memory can be shared between parent and child, leading to communication. You may want to wrap that memory in <span><code class="highlighter-rouge">pthread_mutexattr_setpshared(&amp;attrmutex, PTHREAD_PROCESS_SHARED);</code></span> mutex (or a process wide mutex) to prevent race conditions. There are more standard ways of IPC, like pipes! Consider if you type the following into your terminal.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls -1 | cut -d'.' -f1 | uniq | sort | tee dir_contents
</code></pre></div></div>
<p>What does the following code do? Well it <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/1/ls" class="fancy-link">ls</a></code></span>’s the current directory (the -1 means that it outputs one entry per line). The <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/1/cut" class="fancy-link">cut</a></code></span> command then takes everything before the first period. Uniq makes sure all the lines are uniq, sort sorts them and tee outputs to a file. The important part is that bash creates <strong>5 separate processes</strong> and connects their standard outs/stdins with pipes the trail lookssomething like this.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0) ls (1)------&gt;(0) cut (1)-------&gt;(0) uniq (1)------&gt;(0) sort (1)------&gt;(0) tee (1)
</code></pre></div></div>
<p>The numbers in the pipes are the file descriptors for each process and the arrow represents the redirect or where the output of the pipe is going. A POSIX pipe is almost like its real counterpart - you can stuff bytes down one end and they will appear at the other end in the same order. Unlike real pipes however, the flow is always in the same direction, one file descriptor is used for reading and the other for writing. The <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/pipe" class="fancy-link">pipe</a></code></span> system call is used to create a pipe. These file descriptors can be used with <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/read" class="fancy-link">read</a></code></span> and with <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/write" class="fancy-link">write</a></code></span>. A common method of using pipes is to create the pipe before forking in order to communicate with a child process</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>One can use pipes inside of the same process, but there tends to be no added benefit. Here’s an example program that sends a message to itself:</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>The problem with using a pipe in this fashion is that writing to a pipe can block meaning the pipe only has a limited buffering capacity. If the pipe is full the writing process will block! The maximum size of the buffer is system dependent; typical values from 4KB upto 128KB.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<h3 id="pipe-gotchas" class="title-text">Pipe Gotchas</h3>
<p>Here’s a complete example that doesn’t work! The child reads one byte at a time from the pipe and prints it out - but we never see the message! Can you see why?</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>The parent sends the bytes <span><code class="highlighter-rouge">H,i,(space),C...!</code></span> into the pipe (this may block if the pipe is full). The child starts reading the pipe one byte at a time. In the above case, the child process will read and print each character. However it never leaves the while loop! When there are no characters left to read it simply blocks and waits for more</p>
<p>The call <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/putchar" class="fancy-link">putchar</a></code></span> writes the characters out but we never flush the <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/stdout" class="fancy-link">stdout</a></code></span> buffer. i.e. We have transferred the message from one process to another but it has not yet been printed. To see the message we could flush the buffer e.g. <span><code class="highlighter-rouge">fflush(stdout)</code></span> (or <span><code class="highlighter-rouge">printf(\n)</code></span> if the output is going to a terminal). A better solution would also exit the loop by checking for an end-of-message marker,</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>Processes receive the signal SIGPIPE when no process is listening! From the pipe(2) man page -</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>Tip: Notice only the writer (not a reader) can use this signal. To inform the reader that a writer is closing their end of the pipe, you could write your own special byte (e.g. 0xff) or a message ( <span><code class="highlighter-rouge">Bye!</code></span>)</p>
<p>Here’s an example of catching this signal that does not work! Can you see why?</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>The mistake in above code is that there is still a reader for the pipe! The child still has the pipe’s first file descriptor open and remember the specification? All readers must be closed</p>
<p>When forking, <em>It is common practice</em> to close the unnecessary (unused) end of each pipe in the child and parent process. For example the parent might close the reading end and the child might close the writing end (and vice versa if you have two pipes)</p>
<h3 id="why-is-my-pipe-hanging" class="title-text">Why is my pipe hanging?</h3>
<p>Reads and writes hang on Named Pipes until there is at least one reader and one writer, take this</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>Any <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/open" class="fancy-link">open</a></code></span> is called on a named pipe the kernel blocks until another process calls the opposite open. Meaning, echo calls <span><code class="highlighter-rouge">open(.., O_RDONLY)</code></span> but that blocks until cat calls <span><code class="highlighter-rouge">open(.., O_WRONLY)</code></span>, then the programs are allowed to continue.</p>
<h3 id="race-condition-with-named-pipes" class="title-text">Race condition with named pipes</h3>
<p>What is wrong with the following program?</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>This may never print hello because of a race condition. Since you opened the pipe in the first process under both permissions, open won’t wait for a reader because you told the operating system that you are a reader! Sometimes it looks like it works because the execution of the code looks something like this.</p>
<ol>
  <li>
    <p>Process 1: open(O_RDWR) &amp; write()</p>
  </li>
  <li>
    <p>Process 2: open(O_RDONLY) &amp; read()</p>
  </li>
  <li>
    <p>Process 1: close() &amp; exit()</p>
  </li>
  <li>
    <p>Process 2: print() &amp; exit()</p>
  </li>
</ol>
<ol>
  <li>
    <p>Process 1: open(O_RDWR) &amp; write()</p>
  </li>
  <li>
    <p>Process 1: close() &amp; exit()</p>
  </li>
  <li>
    <p>Process 2: open(O_RDONLY) (Blocks indefinitely)</p>
  </li>
</ol>
<h3 id="what-is-filling-up-the-pipe-what-happens-when-the-pipe-becomes-full" class="title-text">What is filling up the pipe? What happens when the pipe becomes full?</h3>
<p>A pipe gets filled up when the writer writes too much to the pipe without the reader reading any of it. When the pipes become full, all writes fail until a read occurs. Even then, a write may partial fail if the pipe has a little bit of space left but not enough for the entire message</p>
<p>To avoid this, usually two things are done. Either increase the size of the pipe. Or more commonly, fix your program design so that the pipe is constantly being read from.</p>
<h3 id="are-pipes-process-safe" class="title-text">Are pipes process safe?</h3>
<p>Yes! Pipe write are atomic up to the size of the pipe. Meaning that if two processes try to write to the same pipe, the kernel has internal mutexes with the pipe that it will lock, do the write, and return. The only gotcha is when the pipe is about to become full. If two processes are trying to write and the pipe can only satisfy a partial write, that pipe write is not atomic – be careful about that!</p>
<h3 id="the-lifetime-of-pipes" class="title-text">The lifetime of pipes</h3>
<p>Unnamed pipes (the kind we’ve seen up to this point) live in memory (do not take up any disk space) and are a simple and efficient form of inter-process communication (IPC) that is useful for streaming data and simple messages. Once all processes have closed, the pipe resources are freed.</p>
<h3 id="want-to-use-pipes-with-printf-and-scanf-use-fdopen" class="title-text">Want to use pipes with printf and scanf? Use fdopen!</h3>
<p>POSIX file descriptors are simple integers 0,1,2,3… At the C library level, C wraps these with a buffer and useful functions like printf and scanf, so we that we can easily print or parse integers, strings etc. If you already have a file descriptor then you can ‘wrap’ it yourself into a FILE pointer using <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fdopen" class="fancy-link">fdopen</a></code></span> :</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>For writing to files this is unnecessary - just use <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fopen" class="fancy-link">fopen</a></code></span> which does the same as <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/open" class="fancy-link">open</a></code></span> and <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fdopen" class="fancy-link">fdopen</a></code></span> However for pipes, we already have a file descriptor - so this is great time to use <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fdopen" class="fancy-link">fdopen</a></code></span></p>
<p>Here’s a complete example using pipes that almost works! Can you spot the error? Hint: The parent never prints anything!</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>Note the unnamed pipe resource will disappear once both the child and parent have exited. In the above example the child will send the bytes and the parent will receive the bytes from the pipe. However, no end-of-line character is ever sent, so <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fscanf" class="fancy-link">fscanf</a></code></span> will continue to ask for bytes because it is waiting for the end of the line i.e. it will wait forever! The fix is to ensure we send a newline character, so that <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fscanf" class="fancy-link">fscanf</a></code></span> will return.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>If you want your bytes to be sent to the pipe immediately, you’ll need to fflush! At the beginning of this course we assumed that file streams are always <em>line buffered</em> i.e. the C library will flush its buffer everytime you send a newline character. Actually this is only true for terminal streams - for other filestreams the C library attempts to improve performance by only flushing when it’s internal buffer is full or the file is closed.</p>
<h3 id="when-do-i-need-two-pipes" class="title-text">When do I need two pipes?</h3>
<p>If you need to send data to and from a child asynchronously, then two pipes are required (one for each direction). Otherwise the child would attempt to read its own data intended for the parent (and vice versa)!</p>
</div></div></div>
</div></div>
<div class="pad"><div class="card">
<div class="title"><h2 id="named-pipes" class="title-text">Named Pipes<a class="anchor title-text" href="#named-pipes">#</a>
</h2></div>
































































<div class="container-fluid"><div class="row"><div class="content col-sm-11 .col-sm-offset-1">
<h3 id="how-do-i-create-named-pipes" class="title-text">How do I create named pipes?</h3>
<p>An alternative to <em>unamed</em> pipes is <em>named</em> pipes created using <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/mkfifo" class="fancy-link">mkfifo</a></code></span>.</p>
<p>From the command line: <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/mkfifo" class="fancy-link">mkfifo</a></code></span> From C: <span><code class="highlighter-rouge">int mkfifo(const char pathname, mode_t mode);</code></span></p>
<p>You give it the path name and the operation mode, it will be ready to go! Named pipes take up no space on the disk. What the operating system is essentially telling you when you have a named pipe is that it will create an unnamed pipe that refers to the named pipe, and that’s it! There is no additional magic. This is just for programming convenience if processes are started without forking (meaning that there would be no way to get the file descriptor to the child process for an unnamed pipe)</p>
<h3 id="two-types-of-files" class="title-text">Two types of files</h3>
<p>On linux, there are two abstractions with files. The first is the linux <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/4/fd" class="fancy-link">fd</a></code></span> level abstraction.</p>
<ul>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/open" class="fancy-link">open</a></code></span> takes a path to a file and creates a file descriptor entry in the process table. If the file is not available to you, it errors out.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/read" class="fancy-link">read</a></code></span> takes a number of bytes that the kernel has received and reads them into a user space buffer. If the file is not open in read mode, this will break.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/write" class="fancy-link">write</a></code></span> outputs a number of bytes to a file descriptor. If the file is not open in write mode, this will break. This may be buffered internally.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/close" class="fancy-link">close</a></code></span> removes a file descriptor from a process’ file descriptors. This always succeeds on a valid file descriptor.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/lseek" class="fancy-link">lseek</a></code></span> takes a file descriptor and moves it to a certain position. Can fail if the seek is out of bounds.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fcntl" class="fancy-link">fcntl</a></code></span> is the catch all function for file descriptors. You can do everything with this function. Set file locks, read, write, edit permissions, etc …</p>
  </li>
  <li>
    <p>…</p>
  </li>
</ul>
<p>And so on. The linux interface is very powerful and expressive, but sometimes we need portability (for example if we are writing for a mac or windows). This is where C’s abstraction comes into play. On different operating systems, C uses the low level functions to create a wrapper around files you can use everywhere, meaning that C on linux uses the above calls.</p>
<ul>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fopen" class="fancy-link">fopen</a></code></span> opens a file and returns an object. <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/4/null" class="fancy-link">null</a></code></span> is returned if you don’t have permission for the file.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fread" class="fancy-link">fread</a></code></span> reads a certain number of bytes from a file. An error is returned if already at the end of file when which you must call <span><code class="highlighter-rouge">feof()</code></span> in order to check.</p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge">fgetc/fgets</code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fscanf" class="fancy-link">fscanf</a></code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fwrite" class="fancy-link">fwrite</a></code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fprintf" class="fancy-link">fprintf</a></code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fclose" class="fancy-link">fclose</a></code></span></p>
  </li>
  <li>
    <p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fflush" class="fancy-link">fflush</a></code></span></p>
  </li>
</ul>
<p>But you don’t get the expressiveness that linux gives you with system calls you can convert back and forth between them with <span><code class="highlighter-rouge">int fileno(FILE* stream)</code></span> and <span><code class="highlighter-rouge">FILE* fdopen(int fd...)</code></span></p>
<p>Another important aspect to note is the C files are <strong>buffered</strong> meaning that their contents may not be written right away by default. You can can change that with C options.</p>
<h3 id="how-do-i-tell-how-large-a-file-is" class="title-text">How do I tell how large a file is?</h3>
<p>For files less than the size of a long, using fseek and ftell is a simple way to accomplish this:</p>
<p>Move to the end of the file and find out the current position.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>This tells us the current position in the file in bytes - i.e. the length of the file!</p>
<p><span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/fseek" class="fancy-link">fseek</a></code></span> can also be used to set the absolute position.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>All future reads and writes in the parent or child processes will honor this position. Note writing or reading from the file will change the current position.</p>
<p>See the man pages for fseek and ftell for more information.</p>
<h3 id="but-try-not-to-do-this" class="title-text">But try not to do this</h3>
<p><strong>Note: This is not recommended in the usual case because of a quirk with the C language</strong>. That quirk is that longs only need to be <strong>4 Bytes big</strong> meaning that the maximum size that <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/ftell" class="fancy-link">ftell</a></code></span> can return is a little under 2 Gigabytes (which we know nowadays our files could be hundreds of gigabytes or even terabytes on a distributed file system). What should we do instead? Use <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/stat" class="fancy-link">stat</a></code></span>! We will cover stat in a later part but here is some code that will tell you the size of the file</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p><span><code class="highlighter-rouge">buf.st_size</code></span> is of type <span><code class="highlighter-rouge">off_t</code></span> which is big enough for large files.</p>
<h3 id="what-happens-if-a-child-process-closes-a-filestream-using-fclose-or-close" class="title-text">What happens if a child process closes a filestream using fclose or close?</h3>
<p>Closing a file stream is unique to each process. Other processes can continue to use their own file-handle. Remember, everything is copied over when a child is created, even the relative positions of the files.</p>
<h3 id="how-about-mmap-for-files" class="title-text">How about mmap for files?</h3>
<p>One of the general uses for mmap is to map a file to memory. This does not mean that the file is malloc’ed to memory right away. Take the following code for example.</p>
<div class="language-c highlighter-rouge">
<span class="o">&lt;</span>
</div>
<p>The kernel may say, “okay I see that you want to mmap the file into memory, so I’ll reserve some space in your address space that is the length of the file”. That means when you write to addr<span>[</span>0<span>]</span> that you are actually writing to the first byte of the file. The kernel can actually do some optimizations too. Instead of loading the file into memory, it may only load pages at a time because if the file is 1024 pages; you may only access 3 or 4 pages making loading the entire file a waste of time. That is why page faults are so powerful! They let the operating system take control of how much you use your files.</p>
<h3 id="for-every-mmap" class="title-text">For every mmap</h3>
<p>Remember that once you are done <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/mmap" class="fancy-link">mmap</a></code></span>ping that you <span><code class="highlighter-rouge"><a href="https://linux.die.net/man/3/munmap" class="fancy-link">munmap</a></code></span> to tell the operating system that you are no longer using the pages allocated, so the OS can write it back to disk and give you the addresses back in case you need to malloc later.</p>
</div></div></div>
</div></div>
</div>
          
          <div class="wrapper">
</div>
      </div>
      <div class="col-md-2 col-sm-1 col-xs-0"></div>
    </div>
  </div>
  <script>
    var github_repo = "illinois-cs241/illinois-cs241.github.io";
    var github_path = "_wikibook_project/Ipc.md";
  </script>
  <!-- Mathjax takes a while to load so do a lazy load to so we can get accessibility -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" crossorigin="anonymous"></script>

<!-- Again bust cache on the main.js file -->
<script src="/js/main.js?v='2018-11-28 20:00:31 -0600'"></script>

<script>
<footer class="">

<div class="container-fluid">
<div class="shadow"></div>

</div>

</footer>

</body>
</html>
